{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import scipy.constants as const\n",
    "from IPython.core.display import HTML\n",
    "from __future__ import division\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th') # ensure our dimension notation matches\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.layers import Reshape\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.layers.core import Activation, Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D, Conv1D\n",
    "from keras.layers.convolutional import Convolution2D, AveragePooling2D, Conv2DTranspose\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras import utils\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from PIL import Image, ImageOps\n",
    "from functools import partial\n",
    "import random\n",
    "import argparse\n",
    "import math\n",
    "import wavfile24\n",
    "import os\n",
    "import os.path\n",
    "import nnresample \n",
    "\n",
    "import glob\n",
    "\n",
    "NP_RANDOM_SEED = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Model Hyperparameters\n",
    "class BeatGanHyperParameters():\n",
    "    def __init__(self, num_channels, batch_size, model_size, phase_shuffle_size, D_update_per_G_update):\n",
    "        self.c = num_channels\n",
    "        self.b = batch_size\n",
    "        self.d = model_size\n",
    "        self.n = phase_shuffle_size\n",
    "        self.D_updates_per_G_update = D_update_per_G_update\n",
    "        self.WGAN_GP_weight = 10\n",
    "\n",
    "hp = BeatGanHyperParameters(2,64,64,2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=100, output_dim=256*hp.d))\n",
    "    model.add(Reshape((1, 16, 16*hp.d), input_shape = (256*hp.d,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(8*hp.d, (1,25), strides=(1,4), padding=\"same\", data_format='channels_last'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(4*hp.d, (1,25), strides=(1,4), padding=\"same\", data_format='channels_last'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(2*hp.d, (1,25), strides=(1,4), padding=\"same\", data_format='channels_last'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(hp.d, (1,25), strides=(1,4), padding=\"same\", data_format='channels_last'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(hp.c, (1,25), strides=(1,4), padding=\"same\", data_format='channels_last'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Reshape((16384, hp.c), input_shape = (1, 16384, hp.c)))\n",
    "    return model\n",
    "\n",
    "def get_discriminator():\n",
    "    def phase_shuffle(x):\n",
    "        shuffle_amount = random.randint(-1*hp.n, hp.n)\n",
    "        return K.concatenate((x[shuffle_amount:, :], x[:shuffle_amount, :]), axis=0)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(hp.d, 25, strides=4, padding=\"same\", input_shape=(16384, hp.c)))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Lambda(lambda x: phase_shuffle(x)))\n",
    "    model.add(Conv1D(2*hp.d, 25, strides=4, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Lambda(lambda x: phase_shuffle(x)))\n",
    "    model.add(Conv1D(4*hp.d, 25, strides=4, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Lambda(lambda x: phase_shuffle(x)))\n",
    "    model.add(Conv1D(8*hp.d, 25, strides=4, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Lambda(lambda x: phase_shuffle(x)))\n",
    "    model.add(Conv1D(16*hp.d, 25, strides=4, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((256*hp.d, ), input_shape = (1, 16, 16*hp.d)))\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "\n",
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    \"\"\"Calculates the Wasserstein loss for a sample batch.\n",
    "    The Wasserstein loss function is very simple to calculate. In a standard GAN, the discriminator\n",
    "    has a sigmoid output, representing the probability that samples are real or generated. In Wasserstein\n",
    "    GANs, however, the output is linear with no activation function! Instead of being constrained to [0, 1],\n",
    "    the discriminator wants to make the distance between its output for real and generated samples as large as possible.\n",
    "    The most natural way to achieve this is to label generated samples -1 and real samples 1, instead of the\n",
    "    0 and 1 used in normal GANs, so that multiplying the outputs by the labels will give you the loss immediately.\n",
    "    Note that the nature of this loss means that it can be (and frequently will be) less than 0.\"\"\"\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "\n",
    "def gradient_penalty_loss(y_true, y_pred, averaged_samples, gradient_penalty_weight):\n",
    "    \"\"\"Calculates the gradient penalty loss for a batch of \"averaged\" samples.\n",
    "    In Improved WGANs, the 1-Lipschitz constraint is enforced by adding a term to the loss function\n",
    "    that penalizes the network if the gradient norm moves away from 1. However, it is impossible to evaluate\n",
    "    this function at all points in the input space. The compromise used in the paper is to choose random points\n",
    "    on the lines between real and generated samples, and check the gradients at these points. Note that it is the\n",
    "    gradient w.r.t. the input averaged samples, not the weights of the discriminator, that we're penalizing!\n",
    "    In order to evaluate the gradients, we must first run samples through the generator and evaluate the loss.\n",
    "    Then we get the gradients of the discriminator w.r.t. the input averaged samples.\n",
    "    The l2 norm and penalty can then be calculated for this gradient.\n",
    "    Note that this loss function requires the original averaged samples as input, but Keras only supports passing\n",
    "    y_true and y_pred to loss functions. To get around this, we make a partial() of the function with the\n",
    "    averaged_samples argument, and use that for model training.\"\"\"\n",
    "    gradients = K.gradients(K.sum(y_pred), averaged_samples)\n",
    "    gradient_l2_norm = K.sqrt(K.sum(K.square(gradients)))\n",
    "    gradient_penalty = gradient_penalty_weight * K.square(1 - gradient_l2_norm)\n",
    "    return gradient_penalty\n",
    "\n",
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Takes a randomly-weighted average of two tensors. In geometric terms, this outputs a random point on the line\n",
    "    between each pair of input points.\n",
    "    Inheriting from _Merge is a little messy but it was the quickest solution I could think of.\n",
    "    Improvements appreciated.\"\"\"\n",
    "\n",
    "    def _merge_function(self, inputs):\n",
    "        weights = K.random_uniform((64, 1, 1))\n",
    "        return (weights * inputs[0]) + ((1 - weights) * inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_white_noise(sound):\n",
    "    wn = np.random.randint(-10000,10000,(len(sound), hp.c))\n",
    "    sound = sound + wn\n",
    "    return np.clip(sound, -8388608, 8388608-1)\n",
    "    \n",
    "def load_beat_data(policy):\n",
    "    print(\"Loading data\")\n",
    "    X_train = []\n",
    "    normalization_factor = 8388608\n",
    "    num_versions = 5\n",
    "    paths = glob.glob(os.path.normpath(os.getcwd() + '/ULTIMATE_DRUM_LOOPS/*.wav'))\n",
    "    for i in range(len(paths)):\n",
    "        sound = wavfile24.read(paths[i])\n",
    "        if policy == 0:\n",
    "            X_train.append(sound)\n",
    "        elif policy == 1:\n",
    "            wavfile.write('temp.wav', 14700, sound[1][::3])\n",
    "            temp = wavfile.read('temp.wav')\n",
    "            def get_length(path):\n",
    "                if \"125\" in path:\n",
    "                    return 14112\n",
    "                elif \"124\" in path:\n",
    "                    return 14226\n",
    "                return 0\n",
    "            length = get_length(paths[i])\n",
    "            for _ in range(num_versions):\n",
    "                a = add_white_noise (temp[1][:length])/normalization_factor\n",
    "                b = np.zeros((16384 - length, 2))\n",
    "                normed = np.concatenate((a,b))\n",
    "                X_train.append(normed)\n",
    "    return np.array(X_train) if policy == 1 else X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_after_training(BATCH_SIZE):\n",
    "    generator = generator_model()\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    generator.load_weights('goodgenerator.h5')\n",
    "    \n",
    "    noise = np.zeros((BATCH_SIZE, 100))\n",
    "    for i in range(BATCH_SIZE):\n",
    "        noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "    generated_audio = generator.predict(noise, verbose=1)\n",
    "    print(generated_audio.shape)\n",
    "    for audio in generated_audio:\n",
    "        wavfile.write('thing.wav', 14700, audio)\n",
    "\n",
    "def make_generator_model(X_train, generator, discriminator):\n",
    "    for layer in discriminator.layers:\n",
    "        layer.trainable = False\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    generator_input = Input(shape=(100,))\n",
    "    generator_layers = generator(generator_input)\n",
    "    discriminator_layers_for_generator = discriminator(generator_layers)\n",
    "    generator_model = Model(inputs=[generator_input], outputs=[discriminator_layers_for_generator])\n",
    "    \n",
    "    # We use the Adam paramaters from Gulrajani et al.\n",
    "    generator_model.compile(optimizer=Adam(0.0001, beta_1=0.5, beta_2=0.9), loss=wasserstein_loss)\n",
    "    return generator_model\n",
    "\n",
    "def make_discriminator_model(X_train, generator, discriminator):\n",
    "    for layer in discriminator.layers:\n",
    "        layer.trainable = True\n",
    "    for layer in generator.layers:\n",
    "        layer.trainable = False\n",
    "    discriminator.trainable = True\n",
    "    generator.trainable = False\n",
    "    \n",
    "    real_samples = Input(shape=(16384, hp.c))\n",
    "    generator_input_for_discriminator = Input(shape=(100,))\n",
    "    generated_samples_for_discriminator = generator(generator_input_for_discriminator)\n",
    "    discriminator_output_from_generator = discriminator(generated_samples_for_discriminator)\n",
    "    discriminator_output_from_real_samples = discriminator(real_samples)\n",
    "    averaged_samples = RandomWeightedAverage()([real_samples, generated_samples_for_discriminator])\n",
    "    averaged_samples_out = discriminator(averaged_samples)\n",
    "    \n",
    "    partial_gp_loss = partial(gradient_penalty_loss,\n",
    "                          averaged_samples=averaged_samples,\n",
    "                          gradient_penalty_weight=10)\n",
    "    partial_gp_loss.__name__ = 'gradient_penalty'  \n",
    "    \n",
    "    discriminator_model = Model(inputs=[real_samples, generator_input_for_discriminator],\n",
    "                            outputs=[discriminator_output_from_real_samples,\n",
    "                                     discriminator_output_from_generator,\n",
    "                                     averaged_samples_out])\n",
    "    \n",
    "    discriminator_model.compile(optimizer=Adam(0.0001, beta_1=0.5, beta_2=0.9),\n",
    "                            loss=[wasserstein_loss,\n",
    "                                  wasserstein_loss,\n",
    "                                  partial_gp_loss])\n",
    "    return discriminator_model\n",
    "\n",
    "def get_noise(shape):\n",
    "    return np.random.uniform(-1, 1, shape).astype(np.float32)\n",
    "\n",
    "def train(epochs, BATCH_SIZE):\n",
    "    np.random.seed(NP_RANDOM_SEED)\n",
    "    X_train = load_beat_data(1)\n",
    "    np.random.shuffle(X_train)\n",
    "    \n",
    "    discriminator = get_discriminator()\n",
    "    generator = get_generator()\n",
    "    \n",
    "    generator_model = make_generator_model(X_train, generator, discriminator)\n",
    "    discriminator_model = make_discriminator_model(X_train, generator, discriminator)\n",
    "    \n",
    "    positive_y = np.ones((BATCH_SIZE, 1), dtype=np.float32)\n",
    "    negative_y = -positive_y\n",
    "    dummy_y = np.zeros((BATCH_SIZE, 1), dtype=np.float32)\n",
    "    \n",
    "    print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        dl, gl = {}, {}\n",
    "        np.random.shuffle(X_train)\n",
    "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):       \n",
    "            audio_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE].reshape(BATCH_SIZE, 16384, hp.c)\n",
    "            noise = get_noise((BATCH_SIZE, 100))\n",
    "            d_loss = discriminator_model.train_on_batch([audio_batch, noise], [positive_y, negative_y, dummy_y])\n",
    "            dl = d_loss\n",
    "            if index % hp.D_updates_per_G_update == 0:\n",
    "                #print(\"batch %d d_loss : %s\" % (index, d_loss))\n",
    "                noise = get_noise((BATCH_SIZE, 100))\n",
    "                g_loss = generator_model.train_on_batch(noise, positive_y)\n",
    "                gl = g_loss\n",
    "                #print(\"batch %d g_loss : %0.10f\" % (index, g_loss))\n",
    "        \n",
    "        if epoch % 500 == 0:\n",
    "            print(\"epoch %d d_loss : %s\" % (epoch, dl))\n",
    "            print(\"epoch %d g_loss : %0.10f\" % (epoch, gl))\n",
    "            generator.save_weights('weights/generator' + str(epoch) + '.h5', True)\n",
    "            discriminator.save_weights('weights/discriminator' + str(epoch) + '.h5', True)\n",
    "            generate_one(generator, epoch, 0)\n",
    "\n",
    "def generate_one(generator, epoch, index):\n",
    "    noise = get_noise((1,100))\n",
    "    generated_audio = generator.predict(noise, verbose=1)\n",
    "    q = np.array(generated_audio[0]*8388608).astype('int32')\n",
    "    wavfile24.write('outputs/epoch' + (\"%04d\" % epoch) + 'index'+ (\"%03d\" % index) + '.wav', 14700, q, bitrate=24)\n",
    "        \n",
    "def generate_batch(generator, weights_file, batch_size):\n",
    "    noise = get_noise((batch_size,100))\n",
    "    generator.load_weights(weights_file)\n",
    "    generated_audio = generator.predict(noise, verbose=1)\n",
    "    re_normalization_factor = 8388608\n",
    "    assumed_sample_length = 14112\n",
    "    sample_rate = 14700\n",
    "    for i in range(len(generated_audio)):\n",
    "        output = generated_audio[i]\n",
    "        q = np.array(output*re_normalization_factor).astype('int32')\n",
    "        wavfile24.write('generated_outputs/output' + (\"%03d\" % i) + '.wav', sample_rate, np.concatenate((q[:assumed_sample_length], q[:assumed_sample_length])), bitrate=24)\n",
    " \n",
    "# Based on qualitative analysis 0.10 is a good threshold for two samples being alike. Furthermore, audiotory analysis\n",
    "# shows the scores to be relatively well correlated with the similarity of the waveforms. \n",
    "def compute_similarity_score(threshold):\n",
    "    original_beats = load_beat_data(0)\n",
    "    X_train = load_beat_data(1)\n",
    "    generated_outputs = glob.glob(os.path.normpath('/home/narainsk/beat_gan/BeatsByGAN/generated_outputs/*.wav'))\n",
    "    num_similar = 0\n",
    "    normalization_factor = 8388608\n",
    "    num_samples_compared = 14112\n",
    "    for i in range(len(generated_outputs)):\n",
    "        generated_output_file = generated_outputs[i]\n",
    "        b = (wavfile24.read(generated_output_file)[1])/normalization_factor\n",
    "        for i in range(len(original_beats)):\n",
    "            a = X_train[i*5]\n",
    "            error = np.sum(np.square(a[:num_samples_compared] - b[:num_samples_compared]))\n",
    "            similarity = error/(np.sum(np.square(a[:num_samples_compared])))\n",
    "            if similarity <= threshold:\n",
    "                num_similar += 1\n",
    "                break\n",
    "    \n",
    "    print (str(num_similar) + ' similar out of ' + str(len(generated_outputs)))\n",
    "    return (num_similar*1.0)/len(generated_outputs)\n",
    "    \n",
    "#train(6100, hp.b) - this was the original training call, 6k epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/narainsk/miniconda3/envs/beat_gan/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=16384, input_dim=100)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s     \n",
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/narainsk/beat_gan/BeatsByGAN/wavfile24.py:32: WavFileWarning: Unfamiliar format bytes\n",
      "  warnings.warn(\"Unfamiliar format bytes\", WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "9 similar out of 40\n",
      "0.225\n"
     ]
    }
   ],
   "source": [
    "generator = get_generator()\n",
    "generate_batch(generator, 'weights/generator6000.h5', 40)\n",
    "print (compute_similarity_score(0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/narainsk/beat_gan/BeatsByGAN/wavfile24.py:32: WavFileWarning: Unfamiliar format bytes\n",
      "  warnings.warn(\"Unfamiliar format bytes\", WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "9 similar out of 40\n",
      "0.225\n"
     ]
    }
   ],
   "source": [
    "print (compute_similarity_score(0.10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/narainsk/beat_gan/BeatsByGAN/wavfile24.py:32: WavFileWarning: Unfamiliar format bytes\n",
      "  warnings.warn(\"Unfamiliar format bytes\", WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "using file/home/narainsk/beat_gan/BeatsByGAN/generated_outputs/output015.wav\n",
      "56\n",
      "0.0944771932906\n",
      "[[ 1412384  1528271]\n",
      " [-2175288 -2346744]\n",
      " [-2719620 -3184740]\n",
      " [ -599306 -1000781]\n",
      " [  980280   679230]\n",
      " [ 3036766  2878628]]\n",
      "339\n",
      "0.296423343549\n",
      "[[ 1707163  1325793]\n",
      " [-2172580 -2394666]\n",
      " [-3003963 -3255791]\n",
      " [ -931994 -1307497]\n",
      " [ 1113924   747368]\n",
      " [ 3253257  3189736]]\n",
      "347\n",
      "0.224672853009\n",
      "[[ 1848923  1415223]\n",
      " [-2055090 -2303770]\n",
      " [-2905551 -3184642]\n",
      " [ -848912 -1243150]\n",
      " [ 1181088   808796]\n",
      " [ 3342973  3266019]]\n"
     ]
    }
   ],
   "source": [
    "# Test Script that lets you manually check similarity of a generated output vs the training set\n",
    "original_beats = load_beat_data(0)\n",
    "X_train = load_beat_data(1)\n",
    "generated_outputs = glob.glob(os.path.normpath('/home/narainsk/beat_gan/BeatsByGAN/generated_outputs/*.wav'))\n",
    "generated_output_file = generated_outputs[15]\n",
    "print ('using file' + generated_output_file)\n",
    "normalization_factor = 8388608\n",
    "num_samples_compared = 14112\n",
    "b = (wavfile24.read(generated_output_file)[1])/normalization_factor\n",
    "for i in range(len(original_beats)):\n",
    "    a = X_train[i*5]\n",
    "    error = np.sum(np.square(a[:num_samples_compared] - b[:num_samples_compared]))\n",
    "    similarity = error/(np.sum(np.square(a[:num_samples_compared])))\n",
    "    if similarity < 0.5:\n",
    "        print (i)\n",
    "        print (similarity)\n",
    "        print (original_beats[i][1][:6])\n",
    "        wavfile24.write('similarities_test/similar' + str(i) + '.wav', 44100, original_beats[i][1] , bitrate=24)\n",
    "        wavfile24.write('similarities_test/similar' + str(i) + 'downsampled.wav', 14700, original_beats[i][1][::3] , bitrate=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/narainsk/beat_gan/BeatsByGAN/wavfile24.py:32: WavFileWarning: Unfamiliar format bytes\n",
      "  warnings.warn(\"Unfamiliar format bytes\", WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "16\n",
      "out of\n",
      "40\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "# Based on qualitative analysis 0.05 is a good threshold for two samples being alike. Furthermore, audiotory analysis\n",
    "# shows the scores to be relatively well correlated with the similarity of the waveforms. \n",
    "def compute_similarity_score(threshold):\n",
    "    original_beats = load_beat_data(0)\n",
    "    X_train = load_beat_data(1)\n",
    "    generated_outputs = glob.glob(os.path.normpath('/home/narainsk/beat_gan/BeatsByGAN/generated_outputs/*.wav'))\n",
    "    num_similar = 0\n",
    "    normalization_factor = 8388608\n",
    "    num_samples_compared = 14112\n",
    "    for i in range(len(generated_outputs)):\n",
    "        generated_output_file = generated_outputs[i]\n",
    "        b = (wavfile24.read(generated_output_file)[1])/normalization_factor\n",
    "        for i in range(len(original_beats)):\n",
    "            a = X_train[i*5]\n",
    "            error = np.sum(np.square(a[:num_samples_compared] - b[:num_samples_compared]))\n",
    "            similarity = error/(np.sum(np.square(a[:num_samples_compared])))\n",
    "            if similarity <= threshold:\n",
    "                num_similar += 1\n",
    "    \n",
    "    print (num_similar)\n",
    "    print ('out of')\n",
    "    print (len(generated_outputs))\n",
    "    return (num_similar*1.0)/len(generated_outputs)\n",
    "\n",
    "print (compute_similarity_score(0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wavegan_paper_drumhit_data(policy):\n",
    "    print(\"Loading data\")\n",
    "    X_train = []\n",
    "    skip_list = set(['/home/narainsk/beat_gan/BeatsByGAN/drums/Roland JV 1080/MaxV - Guiro.wav'])\n",
    "    normalization_factor = 32768\n",
    "    paths = glob.glob(os.path.normpath(os.getcwd() + '/drums/*/*.wav'))\n",
    "    for i in range(len(paths)):\n",
    "        if paths[i] not in skip_list:\n",
    "            sound = wavfile.read(paths[i])\n",
    "            if policy == 0:\n",
    "                X_train.append(sound)\n",
    "            elif policy == 1:\n",
    "                if sound[1].size <= 44100:\n",
    "                    wavfile.write('temp.wav', 14700, sound[1][::3])\n",
    "                    temp = wavfile.read('temp.wav')\n",
    "                    normed = np.concatenate((temp[1], np.zeros(16384 - len(temp[1]))))/normalization_factor\n",
    "                    X_train.append(normed)\n",
    "    return np.array(X_train) if policy == 1 else X_train\n",
    "X_train = load_wavegan_paper_drumhit_data(1)\n",
    "np.random.shuffle(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfile24.write('a.wav', 44100, X_train[0][1], bitrate=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a7668e7b216b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'paths' is not defined"
     ]
    }
   ],
   "source": [
    "paths[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sound = wavfile24.read(paths[0])\n",
    "sound = wavfile24.read('/home/narainsk/beat_gan/BeatsByGAN/ULTIMATE_DRUM_LOOPS/tr07_drlp_124_Complete_Full.wav')\n",
    "wavfile24.write('temp_start.wav', 44100, sound[1], bitrate=24)\n",
    "wavfile24.write('temp_downsampled.wav', 14700, sound[1][::3], bitrate=24)\n",
    "temp_downsampled = wavfile24.read('temp_downsampled.wav')\n",
    "wavfile24.write('temp_reupsampled.wav', 44100, nnresample.resample(temp_downsampled[1], 44100, 14700), bitrate=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.n = 2\n",
    "#shuffle_amount = random.randint(-1*hp.n, hp.n)\n",
    "print (shuffle_amount)\n",
    "x = a[1].reshape(len(a[1]),1)\n",
    "print (x)\n",
    "print (x[shuffle_amount:, :])\n",
    "print (x[:shuffle_amount, :])\n",
    "combined = np.concatenate((x[shuffle_amount:, :], x[:shuffle_amount, :]), axis=0)\n",
    "print (combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = get_generator()\n",
    "generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "generator.load_weights('goodgenerator.h5')\n",
    "noise = np.random.normal(0, 1, (1, 100))\n",
    "print (noise[:,0:10])\n",
    "generated_audio = generator.predict(noise, verbose=1)\n",
    "q = np.array(generated_audio[0]*32768).astype('int16')\n",
    "print (generated_audio[0][0:10])\n",
    "print (q[0:10])\n",
    "wavfile.write('thing1.wav', 14700, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06183016,  0.11935139],\n",
       "       [-0.00069547,  0.09105957],\n",
       "       [ 0.03382051, -0.05227661],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def add_white_noise(sound):\n",
    "    wn = np.random.randint(-10000,10000,(len(sound), hp.c))\n",
    "    sound = sound + wn\n",
    "    return np.clip(sound, -8388608, 8388608-1)\n",
    "    \n",
    "renormed = np.array(X_train[-100]*8388608).astype('int32')\n",
    "wavfile24.write('a_renormed.wav',14700, renormed, bitrate=24)\n",
    "wavfile24.write('a_renormed_wn.wav',14700, add_white_noise(renormed), bitrate=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900.0692443847656, -7692914, 8378955)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(renormed), np.min(renormed), np.max(renormed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1897.4014892578125, -7694340, 8379862)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = add_white_noise(renormed)\n",
    "np.mean(a), np.min(a), np.max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8367980, -6697630)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(add_white_noise(renormed)), np.min(add_white_noise(renormed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_factor = 32786\n",
    "a = X_train[1345]\n",
    "print (a)\n",
    "print (min(a[1]), max(a[1]), a[1].size)\n",
    "wavfile.write('a.wav', 44100, a[1])\n",
    "print(a[1][::3])\n",
    "wavfile.write('a_14700.wav', 14700, a[1][::3])\n",
    "normed = (a[1][::3]/normalization_factor)\n",
    "renormed = np.array(normed*normalization_factor).astype('int16')\n",
    "print (renormed)\n",
    "wavfile.write('a_renormed.wav',14700, renormed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_factor = 32786\n",
    "a = X_train[2401]\n",
    "print (a)\n",
    "print (a[1].shape)\n",
    "wavfile.write('a.wav', 44100, a[1])\n",
    "if a[1].size <= 44100:\n",
    "    wavfile.write('temp.wav', 14700, a[1][::3])\n",
    "    temp = wavfile.read('temp.wav')\n",
    "    normed = np.concatenate((temp[1], np.zeros(16384 - len(temp[1]))))/normalization_factor\n",
    "    print (normed)\n",
    "    renormed = np.array(normed*normalization_factor).astype('int16')\n",
    "    wavfile.write('a_renormed.wav',14700, renormed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist([len(i) for i in x], bins=\"auto\")\n",
    "plt.show()\n",
    "max_1 = 250000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([len(i) for i in x if len(i) < max_1], bins=\"auto\")\n",
    "plt.show()\n",
    "max_2 = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([len(i) for i in x if len(i) < max_2], bins=\"auto\")\n",
    "plt.show()\n",
    "max_3 = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([len(i) for i in x if len(i) < max_3], bins=\"auto\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxes = [1e99, max_1, max_2, max_3]\n",
    "for m in maxes:\n",
    "    print (len([len(i) for i in x if len(i) < m]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob(os.path.normpath(os.getcwd() + '/drums/*/*.wav'))\n",
    "lens = []\n",
    "for i in range(len(paths)):\n",
    "    if i != 4963:\n",
    "        x = wavfile.read(paths[i])\n",
    "        if x[0] != 44100:\n",
    "            print (x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function wavfile24.read>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "np.random.seed(NP_RANDOM_SEED)\n",
    "np.random.shuffle(X_train)\n",
    "data = X_train[:BATCH_SIZE]\n",
    "data = data.reshape(BATCH_SIZE, 16384, 1)\n",
    "\n",
    "noise = np.zeros((BATCH_SIZE, 100))\n",
    "for i in range(BATCH_SIZE):\n",
    "    noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "generator = generator_model()\n",
    "generated_data = generator.predict(noise, verbose=0)\n",
    "\n",
    "discriminator = discriminator_model()\n",
    "d_optim = Adam(lr=1e-4, beta_1=0.5, beta_2=0.9)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "discriminator.trainable = True\n",
    "X = np.concatenate((data, generated_data))\n",
    "y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "\n",
    "for i in range(100):\n",
    "    d_loss = discriminator.train_on_batch(X, y)\n",
    "    print(\"batch %d d_loss : %0.10f\" % (i, d_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "np.random.seed(NP_RANDOM_SEED)\n",
    "np.random.shuffle(X_train)\n",
    "data = X_train[:BATCH_SIZE]\n",
    "data = data.reshape(BATCH_SIZE, 16384, 1).astype('float32')\n",
    "\n",
    "noise = np.zeros((BATCH_SIZE, 100))\n",
    "for i in range(BATCH_SIZE):\n",
    "    noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "generator = generator_model()\n",
    "generated_data = generator.predict(noise, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
